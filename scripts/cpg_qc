#!/bin/env python

from os.path import join, splitext
import time
from typing import List, Optional, Tuple
import click
import logging
import pandas as pd
import hail as hl

from gnomad.resources.grch38 import telomeres_and_centromeres
from gnomad.sample_qc.filtering import compute_stratified_sample_qc
from gnomad.sample_qc.pipeline import annotate_sex
from gnomad.utils.annotations import bi_allelic_expr
from gnomad.utils.filtering import filter_to_autosomes
from gnomad.utils.filtering import add_filters_expr

from cpg_qc.utils import file_exists, get_validation_callback
from cpg_qc import hard_filtering, pop_strat_qc, utils
from cpg_qc import _version

logger = logging.getLogger("cpg_qc")
logger.setLevel('INFO')

DEFAULT_REF = 'GRCh38'

PATH_MAP = {
    'sample_qc_ht':                       'sample_qc.ht',
    'sample_qc_bi_allelic_ht':            'sample_qc_bi_allelic.ht',
    'sex_ht':                             'sex.ht',
    'hard_filters_ht':                    'hard_filters.ht',
    'meta_ht':                            'metadata.ht',
    'meta_tsv':                           'metadata.tsv.gz',
    'ancestry_training_ht':               'ancestry_training.ht',
    # pop_strat_qc() outputs:
    'pop_ht':                             'pop.ht',  # Inferred sample populations
    'pca_related_samples_to_drop_ht':     'pca_related_samples_to_drop.ht',
    'stratified_metrics_ht':              'stratified_metrics.ht',
    'regressed_metrics_ht':               'regressed_metrics.ht',
    'release_related_samples_to_drop_ht': 'release_related_samples_to_drop.ht',
}


def init_hail(name, local_tmp_dir):
    timestamp = time.strftime('%Y%m%d-%H%M')
    hl_log = join(utils.safe_mkdir(join(local_tmp_dir, 'log')),
                  f'{name}-{timestamp}.log')
    hl.init(default_reference=DEFAULT_REF, log=hl_log)


@click.command()
@click.version_option(_version.__version__)
@click.option('--sample-map', 'sample_map_csv_path', required=True,
              callback=get_validation_callback(ext='csv', must_exist=True),
              help='path to a per-sample data in a CSV file with '
              'a first line as a header. The allowed columns are the following:\n'
              'sample,population,gvcfs,contamination,alignment_summary_metrics,'
              'duplicate_metrics,insert_size_metrics,wgs_metrics\n'
              'The first column is the only required one, and corresponds '
              'the sample ID. Samples with non-empty entries in '
              'the "population" column will be used to train the random forest '
              'for population inferral of remaining samples. Other colums are '
              'used to apply QC hard filters to samples.')
@click.option('--mt', 'mt_path', required=True,
              callback=get_validation_callback(ext='mt', must_exist=True),
              help='path to the input MatrixTable. Must have an .mt extention. '
              'Can be a Google Storage URL (i.e. start with `gs://`). '
              'To generate it, you can run the `combine_gvcfs` script with the '
              'same `--sample-map` input.')
@click.option('--bucket', 'work_bucket', required=True, help=
              'path to folder for intermediate output. '
              'Can be a Google Storage URL (i.e. start with `gs://`).')
@click.option('--local-tmp-dir', 'local_tmp_dir', required=True, help=
              'local directory for temporary files and Hail logs (must be local)')
@click.option('--overwrite', 'overwrite', is_flag=True, help=
              'if an intermediate or a final file exists, skip running the code '
              'that generates it')
@click.option('--min-cov', 'min_cov', default=18,
              help='minimum coverage for inclusion when computing har-filters')
@click.option('--kin-threshold', 'kin_threshold', default=0.1,
              help='maximum kin threshold to be considered unrelated')
@click.option('--n-pcs', 'n_pcs', default=30,
              help='number of PCs to compute for ancestry PCA')
@click.option('--min-pop-prob', 'min_pop_prob', default=0.9,
              help='minimum RF prob for pop assignment')
@click.option('--filtering-qc-metrics', 'filtering_qc_metrics',
              help="List of QC metrics for filtering.",
              default=','.join([
                  'n_snp', 'n_singleton', 'r_ti_tv',
                  'r_insertion_deletion', 'n_insertion', 'n_deletion',
                  'r_het_hom_var', 'n_het', 'n_hom_var', 'n_transition',
                  'n_transversion']))

def main(
        sample_map_csv_path,
        mt_path: str,
        work_bucket: str,
        local_tmp_dir: str,
        overwrite: bool,
        min_cov: int,
        kin_threshold: float,
        n_pcs: int,
        min_pop_prob: float,
        filtering_qc_metrics: str,
):
    sample_df = pd.read_csv(sample_map_csv_path, sep=',')
    path_map = {name: join(work_bucket, p) for name, p in PATH_MAP.items()}

    init_hail('sample_qc', local_tmp_dir)
    mt = hl.read_matrix_table(mt_path)

    sample_qc_ht, sample_qc_bi_allelic_ht = _compute_sample_qc(
        mt,
        sample_qc_ht_path=path_map['sample_qc_ht'],
        sample_qc_bi_allelic_ht_path=path_map['sample_qc_bi_allelic_ht'],
        tmp_ht_prefix=splitext(path_map['sample_qc_ht'])[0],
        overwrite=overwrite
    )

    sex_ht = _infer_sex(
        mt,
        sex_ht_path=path_map['sex_ht'],
        overwrite=overwrite)

    hard_filters_ht = hard_filtering.compute_hard_filters(
        mt,
        sex_ht,
        sample_qc_bi_allelic_ht,
        sample_df,
        hard_filters_ht_path=path_map['hard_filters_ht'],
        work_bucket=work_bucket,
        local_tmp_dir=local_tmp_dir,
        cov_threshold=min_cov,
        overwrite=overwrite
    )

    (pca_related_samples_to_drop_ht,
     pop_ht,
     stratified_metrics_ht,
     regressed_metrics_ht,
     release_related_samples_to_drop_ht) = pop_strat_qc.run_pop_strat_qc(
        mt,
        sample_df,
        work_bucket=work_bucket,
        overwrite=overwrite,

        # Inputs:
        sex_ht=sex_ht,
        hard_filters_ht=hard_filters_ht,
        sample_qc_ht=sample_qc_ht,

        # Outputs:
        pca_related_samples_to_drop_ht_path=path_map[
            'pca_related_samples_to_drop_ht'],
        pop_ht_path=path_map['pop_ht'],
        stratified_metrics_ht_path=path_map['stratified_metrics_ht'],
        regressed_metrics_ht_path=path_map['regressed_metrics_ht'],
        release_related_samples_to_drop_ht_path=path_map[
            'release_related_samples_to_drop_ht'],

        kin_threshold=kin_threshold,
        n_pcs=n_pcs,
        filtering_qc_metrics=filtering_qc_metrics.split(","),
        min_pop_prob=min_pop_prob
    )

    _generate_metadata(
        sample_qc_ht=sample_qc_ht,
        sex_ht=sex_ht,
        hard_filters_ht=hard_filters_ht,
        regressed_metrics_ht=regressed_metrics_ht,
        pop_ht=pop_ht,
        pca_related_samples_to_drop_ht=pca_related_samples_to_drop_ht,
        release_related_samples_to_drop_ht=release_related_samples_to_drop_ht,
        meta_ht_path=path_map['meta_ht'],
        meta_tsv_path=path_map['meta_tsv'],
        overwrite=overwrite
    )


def _compute_sample_qc(
        mt: hl.MatrixTable,
        sample_qc_ht_path: str,
        sample_qc_bi_allelic_ht_path: str,
        tmp_ht_prefix: Optional[str],
        overwrite: bool = False,
) -> Tuple[hl.Table, hl.Table]:
    """
    Run Hail hl.sample_qc to generate a Hail Table with per-sample
    QC metrics. Additionally generates 2 more tables separately for
    bi-allelic and multi-allelic calls with `_bi_allelic.ht` and
    `_multi_allelic.ht` suffixes to the out path name correspondingly.
    """
    if overwrite or not file_exists(sample_qc_ht_path):
        logger.info('Running sample QC')

        mt = filter_to_autosomes(mt)
        mt = mt.filter_rows(
            ~hl.is_defined(telomeres_and_centromeres.ht()[mt.locus]) &
            (hl.len(mt.alleles) > 1))
        mt = mt.select_entries('LGT')

        sample_qc_ht = compute_stratified_sample_qc(
            mt,
            strata={
                'bi_allelic': bi_allelic_expr(mt),
                'multi_allelic': ~bi_allelic_expr(mt)
            },
            tmp_ht_prefix=tmp_ht_prefix,
            gt_col='LGT'
        )

        # Remove annotations that cannot be computed from the sparse format
        sample_qc_ht = sample_qc_ht.annotate(
            **{
                x: sample_qc_ht[x].drop('n_called', 'n_not_called', 'call_rate')
                for x in sample_qc_ht.row_value
            }
        )
        sample_qc_ht = sample_qc_ht.repartition(100)
        sample_qc_ht.write(sample_qc_ht, overwrite=True)

    return (
        hl.read_table(sample_qc_ht_path),
        hl.read_table(sample_qc_bi_allelic_ht_path)
    )


def _infer_sex(
        mt: hl.MatrixTable,
        sex_ht_path: str,
        overwrite: bool = False,
) -> hl.Table:

    if overwrite or not file_exists(sex_ht_path):
        logger.info('Inferring sex')
        annotate_sex(
            mt,
            excluded_intervals=telomeres_and_centromeres.ht(),
            aaf_threshold=0.001,
            f_stat_cutoff=0.5,
            gt_expr="LGT",
        ).write(sex_ht_path, overwrite=True)
    return hl.read_table(sex_ht_path)


def _generate_metadata(
        sample_qc_ht: hl.Table,
        sex_ht: hl.Table,
        hard_filters_ht: hl.Table,
        regressed_metrics_ht: hl.Table,
        pop_ht: hl.Table,
        pca_related_samples_to_drop_ht: hl.Table,
        release_related_samples_to_drop_ht: hl.Table,
        meta_tsv_path: str,
        meta_ht_path: str,
        overwrite: bool = False,
) -> hl.Table:

    if overwrite or not file_exists(meta_tsv_path):
        logger.info('Generate the metadata HT and TSV files')

        meta_ht = sex_ht.transmute(
            impute_sex_stats=hl.struct(
                f_stat=sex_ht.f_stat,
                n_called=sex_ht.n_called,
                expected_homs=sex_ht.expected_homs,
                observed_homs=sex_ht.observed_homs
            )
        )

        meta_ht = meta_ht.annotate_globals(
            **regressed_metrics_ht.index_globals()
        )

        meta_ht = meta_ht.annotate(
            sample_qc=sample_qc_ht[meta_ht.key].sample_qc,
            **hard_filters_ht[meta_ht.key],
            **regressed_metrics_ht[meta_ht.key],
            **pop_ht[meta_ht.key],
            release_related=hl.is_defined(release_related_samples_to_drop_ht[meta_ht.key]),
            all_samples_related=hl.is_defined(pca_related_samples_to_drop_ht[meta_ht.key]),
        )

        meta_ht = meta_ht.annotate(
            hard_filters=hl.or_else(meta_ht.hard_filters, hl.empty_set(hl.tstr)),
            sample_filters=add_filters_expr(
                filters={
                    'related': meta_ht.release_related
                },
                current_filters=meta_ht.hard_filters.union(meta_ht.qc_metrics_filters)
            )
        )

        meta_ht = meta_ht.annotate(
            high_quality=(hl.len(meta_ht.hard_filters) == 0) &
                         (hl.len(meta_ht.qc_metrics_filters) == 0),
            release=hl.len(meta_ht.sample_filters) == 0
        )

        meta_ht.checkpoint(meta_ht_path, overwrite=overwrite, _read_if_exists=not overwrite)

        n_pcs = meta_ht.aggregate(hl.agg.min(hl.len(meta_ht.pca_scores)))
        meta_ht = meta_ht.transmute(
            **{f'PC{i + 1}': meta_ht.pca_scores[i] for i in range(n_pcs)},
            hard_filters=hl.or_missing(hl.len(meta_ht.hard_filters) > 0,
                                       hl.delimit(meta_ht.hard_filters)),
            qc_metrics_filters=hl.or_missing(hl.len(meta_ht.qc_metrics_filters) > 0,
                                             hl.delimit(meta_ht.qc_metrics_filters))
        )
        meta_ht.flatten().export(meta_tsv_path)

    return hl.read_table(meta_ht_path)


if __name__ == '__main__':
    main()


