import os
import pandas as pd

SHOW_POPS_FOR = ['NA12878', 'NA19238']
PICARD_SUFFIX_D = {
    'contamination': 'selfSM',
    'alignment_summary_metrics': 'alignment_summary_metrics',
    'duplicate_metrics': 'duplicate_metrics',
    'insert_size_metrics': 'insert_size_metrics',
    'wgs_metrics': 'wgs_metrics',
}
samples = pd.read_csv('resources/samples.ped', sep='\t')
# We are recycling files for 3 samples to make the toy dataset even smaller
PICARD_FILES_SAMPLE_MAP = {'NA12878': 'NA19238', 'NA12891': 'NA19239', 'NA12892': 'NA19240'}


rule all:
    input:
        all = 'sample_maps/toy.local.csv',
        round1 = 'sample_maps/round1.local.csv',
        round2 = 'sample_maps/round2.local.csv',

rule ref_fa_dict:
    output:
        'resources/Homo_sapiens_assembly38.dict',
    params:
        ref_url = 'gs://genomics-public-data/references/hg38/v0',
    shell:
        "gsutil cp {params.ref_url}/Homo_sapiens_assembly38.dict -"
        " | awk '{{ if ($1 ~ /@HD/ || $2 ~ /^SN:chr[0-9YXM]+$/) print $0}}'"
        " > {output}"

rule ref_fa_fai:
    output:
        'resources/Homo_sapiens_assembly38.fasta.fai',
    params:
        ref_url = 'gs://genomics-public-data/references/hg38/v0',
    shell:
        "gsutil cp {params.ref_url}/Homo_sapiens_assembly38.fasta.fai -"
        " | awk '{{ if ($1 ~ /^chr[0-9YXM]+$/) print $0}}'"
        " > {output}"

rule ref_fa:
    output:
        'resources/Homo_sapiens_assembly38.fasta',
    shell:
        'touch {output}'

rule prep_bed:
    output:
        'resources/toy_regions.bed'
    shell:
        "gsutil cp gs://playground-au/CDS-canonical.bed -"
        " | awk 'BEGIN {{srand()}} {{ if (rand() <= .1 && $1 !~ /alt/"
        " || $1 ~ /chrY/) print $0}}' > {output}"

rule subset_gvcf:
    input:
        regions = rules.prep_bed.output
    output:
        gvcf = 'work/toy_regions/{sample}.g.vcf.gz',
        tbi = 'work/toy_regions/{sample}.g.vcf.gz.tbi'
    shell:
         "gsutil cp gs://playground-au/gvcf/{wildcards.sample}.g.vcf.gz -"
         " | bcftools view -T {input.regions} -Oz -o {output.gvcf} "
         "&& tabix -p vcf {output.gvcf}"

# Reblocking GVCFs to significantly reduce their size
rule reblock_gvcf:
    input:
        gvcf = rules.subset_gvcf.output.gvcf,
        tbi = rules.subset_gvcf.output.tbi,
        ref_fa = rules.ref_fa.output,
        ref_fa_fai = rules.ref_fa_fai.output,
        ref_fa_dict = rules.ref_fa_dict.output,
    output:
        gvcf = 'work/reblocked/{sample}.g.vcf.gz',
        tbi = 'work/reblocked/{sample}.g.vcf.gz.tbi'
    shell:
        "gatk ReblockGVCF --drop-low-quals"
        " -R {input.ref_fa}"
        " -V {input.gvcf} -O {output.gvcf}"

rule clean_info_fields:
    input:
        gvcf = rules.reblock_gvcf.output.gvcf
    output:
        gvcf = 'gvcfs/{sample}.g.vcf.gz',
        tbi = 'gvcfs/{sample}.g.vcf.gz.tbi',
    params:
        to_clean = ','.join(f'INFO/{anno}' for anno in [
            'AS_RAW_BaseQRankSum',
            'AS_RAW_MQ',
            'AS_RAW_MQRankSum',
            'AS_RAW_ReadPosRankSum',
            'AS_SB_TABLE',
            'MQ_DP',
        ])
    shell:
        'bcftools annotate -x "{params.to_clean}" '
        '{input.gvcf} -Oz -o {output.gvcf} && tabix {output.gvcf}'

rule copy_picard_file:
    params:
        bucket = 'gs://playground-au/warp/output/WholeGenomeGermlineSingleSample',
        fname = lambda wildcards: f'{wildcards.sample}.{wildcards.suffix}'
    output:
        'picard_files/{sample}.{suffix}'
    shell:
        'gsutil cp "{params.bucket}/**/{params.fname}" picard_files/'

rule make_csv:
    input:
        gvcfs = expand(rules.clean_info_fields.output, sample=samples['Individual.ID']),
        picard_files = expand(
            rules.copy_picard_file.output,
            sample=PICARD_FILES_SAMPLE_MAP.values(),
            suffix=PICARD_SUFFIX_D.values(),
        )
    output:
        all = 'sample_maps/toy.local.csv',
        round1 = 'sample_maps/round1.local.csv',
        round2 = 'sample_maps/round2.local.csv',
    run:
        rows = []
        hdr = ['sample', 'population', 'gvcf'] + list(PICARD_SUFFIX_D.keys())
        for sample, pop, gvcf in zip(
                samples['Individual.ID'],
                samples['Population'],
                input.gvcfs
            ):
            row = dict(sample=sample, gvcf=f'data/{gvcf}',
                population=pop if sample in SHOW_POPS_FOR else '')
            for picard_key, picard_suffix in PICARD_SUFFIX_D.items():
                picard_sample = PICARD_FILES_SAMPLE_MAP.get(sample, sample)
                picard_fpath = f'picard_files/{picard_sample}.{picard_suffix}'
                if os.path.isfile(picard_fpath):
                    row[picard_key] = f'data/{picard_fpath}'
                else:
                    row[picard_key] = ''
            rows.append(row)
        with open(output.all, 'w') as out, open(output.round1, 'w') as out_r1, \
                open(output.round2, 'w') as out_r2:
            out.write(','.join(hdr) + '\n')
            out_r1.write(','.join(hdr) + '\n')
            out_r2.write(','.join(hdr) + '\n')
            for row in rows:
                out.write(','.join(row[h] for h in hdr) + '\n')
            for row in rows[:3]:
                out_r1.write(','.join(row[h] for h in hdr) + '\n')
            for row in rows[3:]:
                out_r2.write(','.join(row[h] for h in hdr) + '\n')

